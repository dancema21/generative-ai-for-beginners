{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORT MODULES AND SET CONSTANTS\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "THRESHOLD = 0.2\n",
    "\n",
    "model = SentenceTransformer(\"google/embeddinggemma-300m\")\n",
    "path = \"/workspaces/generative-ai-for-beginners/08-building-search-applications/embedding_index_3m.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOAD DATASET \n",
    "##### import embedding json as Panda Dataframe\n",
    "\n",
    "def load_dataset(path: str) -> pd.core.frame.DataFrame:\n",
    "    data = pd.read_json(path)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    if len(a) > len(b):\n",
    "        b = np.pad(b, (0, len(a) - len(b)), 'constant')\n",
    "    if len(a) < len(b):\n",
    "        a = np.pad(a, (0,len(b) - len(a)), 'constant')\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GET VIDEOS \n",
    "###### embbed the input of the user\n",
    "###### define cosine similarity to compare 2 embeddings\n",
    "###### create new column which is the result of comparing the input to each embedded text using cosine similarity\n",
    "###### filter out results below thresold\n",
    "###### select the top 5 similar outputs\n",
    "\n",
    "def get_videos(query: str, data: pd.core.frame.DataFrame, number_results: int) -> pd.core.frame.DataFrame:\n",
    "    query_embedding = model.encode(query)\n",
    "    video_vectors = data.copy()\n",
    "    video_vectors['similarity'] = video_vectors['ada_v2'].apply(lambda x: cosine_similarity(x,query_embedding))\n",
    "    #video_vectors = video_vectors[video_vectors['similarity'] > THRESHOLD].copy()\n",
    "    video_vectors = video_vectors.sort_values(by='similarity', ascending = False).head(number_results)\n",
    "    return video_vectors\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DISPLAY RESULTS\n",
    "##### output with following format for each video result : - video name, url, ..\n",
    "\n",
    "def display_results(videos: pd.core.frame.DataFrame, query: str) -> str:\n",
    "    text = f\"Here are the results for : {query}\"\n",
    "    for video in videos.itertuples():\n",
    "        text += f\"\"\"\n",
    "        - {video.title}\n",
    "        URL : https://youtu.be/{video.videoId}?t={video.seconds}\n",
    "        Summary : {video.summary}\n",
    "        Speaker : {video.speaker}\n",
    "        Similarity score : {round(video.similarity,3)}\n",
    "        \"\"\"\n",
    "    print(text)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the results for : embedding\n",
      "        - What's new with Speech: Custom Neural Voice now in GA\n",
      "        URL : https://youtu.be/HG7HxkTYGzw?t=924\n",
      "        Summary : The video discusses the process of creating a synthetic voice using a new microphone. It emphasizes the importance of obtaining consent from voice actors and ensuring their involvement in the training process. The video also highlights the use of speech-to-text and speaker recognition technologies to validate the accuracy and authenticity of the voice recordings. Finally, it mentions the recommended minimum number of lines for training and the availability of pre-built test lines.\n",
      "        Speaker : Seth, Edward, Sarah\n",
      "        Similarity score : 0.038\n",
      "        \n",
      "        - AI Show Custom Skills In Azure Cognitive Search\n",
      "        URL : https://youtu.be/fHLCE-NZeb4?t=735\n",
      "        Summary : The video demonstrates how to connect an Azure Function to the rest of a pipeline for consuming data. The Azure Function is a custom skill that takes input from an indexer and returns output that the indexer can read. The video shows how to modify the index to include an extra field, and how to modify the skill set to include the custom skill. The custom skill is then connected to the rest of the pipeline for further processing.\n",
      "        Speaker : Luis, Seth\n",
      "        Similarity score : 0.035\n",
      "        \n",
      "        - Intro to PyTorch Tutorial: Building fashion recognizer\n",
      "        URL : https://youtu.be/f6xjO9S2ToI?t=0\n",
      "        Summary : Dmytro Dzhulgakov, a core contributor for PyTorch, provides an introductory hands-on tutorial for building a fashion recognizer using PyTorch. He covers core functionality, network architecture, loss function and optimizer, and setting up TensorBoard. PyTorch is an open-source machine learning framework that accelerates the path from research to production deployment. The tutorial showcases the ease of use and interoperability of PyTorch with other libraries like NumPy.\n",
      "        Speaker : Dmytro Dzhulgakov\n",
      "        Similarity score : 0.034\n",
      "        \n",
      "        - Improving customer experiences with Speech to Text and Text to Speech | AI Show\n",
      "        URL : https://youtu.be/XgmohMfwUgc?t=930\n",
      "        Summary : Neuro, an AI training platform, now offers a new feature that allows users to transfer trained voices to different languages. By selecting the training data and speaker files, users can train a voice in one language and make it speak in another. The process typically takes several hours, but pre-trained voices in German, Spanish, French, and Japanese are already available. The platform also includes a content creation tool for audio recordings in multiple languages.\n",
      "        Speaker : Edward Un, Heiko Rahmel\n",
      "        Similarity score : 0.034\n",
      "        \n",
      "        - The AI Show: Ep 56 | Create a Custom Neural Voice \"Lite\" for Brands and Characters with Veritone\n",
      "        URL : https://youtu.be/nijflt8YBLQ?t=0\n",
      "        Summary : Qinying Liao and Ashley Bailey from Veritone introduce Custom Neural Voice \"Lite,\" a new feature in public preview that allows users to clone their voice by recording just 5 minutes of speech data. This feature makes it easy for customers to create a synthetic voice that sounds natural for various professional scenarios, such as audiobooks and language learning. The feature also reduces training data and time to market for customers.\n",
      "        Speaker : Qinying Liao, Ashley Bailey, Shinging\n",
      "        Similarity score : 0.032\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "data = load_dataset(path)\n",
    "\n",
    "while True:\n",
    "    query = input(\"What re you interested in ?\") # Ask user input for search\n",
    "    if query == \"stop\":\n",
    "        break\n",
    "    videos = get_videos(query, data, 5)\n",
    "    display_results(videos, query)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
